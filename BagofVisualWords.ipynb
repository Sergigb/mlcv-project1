{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2_Assignment\n",
    "## Team members:\n",
    "- Marc PÃ©rez Quintana  <br>\n",
    "- Basem Elbarashy <br>\n",
    "- Sergi Garcia Bordils <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- We list/explain at the start of each section the defined variables that will be used in the other sections \n",
    "- We assume that you have the following in the current dir:  \n",
    "test/, train/ , test_images_filenames.dat , train_images_filenames.dat, test_labels.dat, train_labels.dat\n",
    "- The code is tested with python 3 and opencv 3.4\n",
    "- Most components are implemented in methods so we can easily play with them at the end of the notebook and tune the hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 400 #number of features for the SIFT detector but for densesift it depends on step value\n",
    "step = 10\n",
    "k = 500 # codebook size / number of clusters for KMeans / number of words\n",
    "num_neighbors = 5 #number of neighbors (k) for the k-nn classifier\n",
    "knn_metric = 'manhattan'#distance for the k-nn classifier\n",
    "denseSift = True #True if Dense SIFT is to be used, False for classical SIFT\n",
    "pyramidDepth = 0 # 0-> No spatial pyramid, 1-> whole image + 4 subimages, 2-> lower levels + 16 subimages, ...\n",
    "\n",
    "\n",
    "normalization = True \n",
    "norm = 'power'  # l2 or power\n",
    "steps = [10]  # [10, 10, 10, 10]  # steps for the different desc sizes\n",
    "kpt_sizes = [10]  # [5, 10, 15, 20]  # desc sizes\n",
    "alpha = 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Read the train and test files\n",
    "- train_images_filenames\n",
    "- test_images_filenames\n",
    "- train_labels\n",
    "- test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Trainset Size =  1881\n",
      "- Trainset classes count :  {'inside_city': 214, 'mountain': 260, 'coast': 244, 'forest': 227, 'Opencountry': 292, 'street': 212, 'highway': 184, 'tallbuilding': 248}\n",
      "- Testset Size =  807\n",
      "- Testset classes count:  {'inside_city': 94, 'mountain': 114, 'coast': 116, 'forest': 101, 'Opencountry': 118, 'street': 80, 'highway': 76, 'tallbuilding': 108}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n",
    "\n",
    "class_count_test = {}\n",
    "for label in test_labels:\n",
    "    if label in class_count_test:\n",
    "        class_count_test[label] += 1\n",
    "    else: \n",
    "        class_count_test[label] = 1\n",
    "        \n",
    "class_count_train = {}\n",
    "for label in train_labels:\n",
    "    if label in class_count_train:\n",
    "        class_count_train[label] += 1\n",
    "    else: \n",
    "        class_count_train[label] = 1\n",
    "\n",
    "print('- Trainset Size = ', len(train_labels))\n",
    "print(\"- Trainset classes count : \", class_count_train)\n",
    "print('- Testset Size = ', len(test_labels))\n",
    "print(\"- Testset classes count: \", class_count_test)\n",
    "\n",
    "plt.bar(range(len(class_count_train)), list(class_count_train.values()), align='center')\n",
    "plt.xticks(range(len(class_count_train)), list(class_count_train.keys()), rotation='vertical')\n",
    "plt.title('Classes Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\\nskf_split = skf.split(train_images_filenames, train_labels)\\n\\nfor train_index, validation_index in skf_split:\\n    print(\"length of validation_index\", len(validation_index))\\n    print(\"VALIDATION:\", validation_index)\\n    class_count = {}\\n    for index in validation_index:\\n        label = train_labels[index]\\n        if label in class_count:\\n            class_count[label] += 1\\n        else: \\n            class_count[label] = 1\\n    print(class_count)\\n    print(\"-------------------------\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "skf_split = skf.split(train_images_filenames, train_labels)\n",
    "\n",
    "for train_index, validation_index in skf_split:\n",
    "    print(\"length of validation_index\", len(validation_index))\n",
    "    print(\"VALIDATION:\", validation_index)\n",
    "    class_count = {}\n",
    "    for index in validation_index:\n",
    "        label = train_labels[index]\n",
    "        if label in class_count:\n",
    "            class_count[label] += 1\n",
    "        else: \n",
    "            class_count[label] = 1\n",
    "    print(class_count)\n",
    "    print(\"-------------------------\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Dense SIFT\n",
    "- compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denseSIFT(images_filenames, labels):\n",
    "    SIFTdetector = cv2.xfeatures2d.SIFT_create(num_features) # Create a SIFT object detector and descriptor\n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "    kpts = []\n",
    "    \n",
    "    if denseSift:\n",
    "        kpt = []\n",
    "        # I moved this here to avoid computing the kpts for every image, since they all have the same size\n",
    "        for step, size in zip(steps, kpt_sizes):  \n",
    "            kpt.extend([cv2.KeyPoint(x, y, size) for y in range(0, 256, step) \n",
    "                                             for x in range(0, 256, step)])\n",
    "    \n",
    "    for filename, labels in zip(images_filenames, labels):\n",
    "        filename = filename.replace(\"../../Databases/MIT_split\", \".\")\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if denseSift:\n",
    "            _, des = SIFTdetector.compute(gray, kpt)\n",
    "\n",
    "        else:\n",
    "            kpt, des = SIFTdetector.detectAndCompute(gray, None)\n",
    "        \n",
    "        if normalization:\n",
    "            if norm == 'l2':\n",
    "                des = normalize(des, norm, axis=0)\n",
    "            if norm == 'power':\n",
    "                des = np.sign(des) * (des**alpha)\n",
    "                \n",
    "        kpts.append(kpt)\n",
    "        descriptors.append(des)\n",
    "        label_per_descriptor.append(labels)\n",
    "\n",
    "    return (kpts, descriptors, np.vstack(descriptors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_words(codebook, descriptors, kpts):\n",
    "    for level in range(pyramidDepth+1):\n",
    "        if(level == 0):\n",
    "            pyramid_visual_words = np.zeros((len(descriptors), k), dtype=np.float32)\n",
    "            for i in range(len(descriptors)):\n",
    "                for word in codebook.predict(descriptors[i]):   \n",
    "                    pyramid_visual_words[i,word]+=1\n",
    "        else:\n",
    "            for x in range(2**level):\n",
    "                    for y in range(2**level): \n",
    "                        visual_words=np.zeros((len(descriptors),k),dtype=np.float32)\n",
    "                        for i in range(len(descriptors)):    \n",
    "                            words = codebook.predict(descriptors[i])\n",
    "                            for keypoint in range(len(descriptors[i])):\n",
    "                                x_pt, y_pt = kpts[i][keypoint].pt\n",
    "                                if (x_pt>=x*256/(2**level) and x_pt<(x+1)*256/(2**level) and y_pt>=x*256/(2**level) and y_pt<(x+1)*256/(2**level)):\n",
    "                                    visual_words[i, words[keypoint]]+=1\n",
    "                        pyramid_visual_words = np.append(pyramid_visual_words, visual_words, axis=1)\n",
    "        #print(pyramid_visual_words.shape)\n",
    "    return pyramid_visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramIntersection(M, N):\n",
    "    n,m = M.shape\n",
    "    K_int = np.zeros(shape=(n,n),dtype=np.float)\n",
    "    \n",
    "    print(M.shape, N.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(M.shape[1]):\n",
    "                K_int[i,j] += min(M[i][k],N[j][k])\n",
    "    \n",
    "    return K_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "### Raw data ==> Densesift descriptors ==> Visual words ==> Visual words pyramid ==> Feature standarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata size:  1881\n",
      "Feature size:  500\n"
     ]
    }
   ],
   "source": [
    "# Densesift descriptors\n",
    "Train_kpts, Train_descriptors, Train_descriptors_vstacked = denseSIFT(train_images_filenames, train_labels)\n",
    "Test_kpts, Test_descriptors, Test_descriptors_vstacked    = denseSIFT(test_images_filenames,   test_labels)\n",
    "\n",
    "# Visual words\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(Train_descriptors_vstacked)\n",
    "\n",
    "#  Visual words pyramid\n",
    "visual_words_train = get_visual_words(codebook, Train_descriptors, Train_kpts)\n",
    "visual_words_test  = get_visual_words(codebook, Test_descriptors, Test_kpts)\n",
    "\n",
    "# Feature standarization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(visual_words_train)\n",
    "visual_words_train = scaler.transform(visual_words_train)\n",
    "visual_words_test  = scaler.transform(visual_words_test)\n",
    "\n",
    "# Compare between data size and feature size\n",
    "print('traindata size: ',visual_words_train.shape[0])\n",
    "print('Feature size: ',visual_words_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.8364312267658\n"
     ]
    }
   ],
   "source": [
    "## Knn classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=num_neighbors,n_jobs=-1,metric=knn_metric)\n",
    "knn.fit(visual_words_train, train_labels)\n",
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.00619578686494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n## SVM classifier with SGD!\\nclf = SGDClassifier(alpha=.0001, n_iter=60, penalty='l2', shuffle=True, random_state=0,verbose=0)\\nclf.fit(visual_words, train_labels)\\naccuracy = 100*clf.score(visual_words_test, test_labels)\\nprint(accuracy)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SVM classifier\n",
    "svm_kernel = 'rbf'  # It must be one of âlinearâ, âpolyâ, ârbfâ, âsigmoidâ, âprecomputedâ or a callable \n",
    "clf = svm.SVC(kernel=svm_kernel, C = 1)\n",
    "clf.fit(visual_words_train, train_labels)\n",
    "accuracy = 100*clf.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "\"\"\"\n",
    "## SVM classifier with SGD!\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=60, penalty='l2', shuffle=True, random_state=0,verbose=0)\n",
    "clf.fit(visual_words, train_labels)\n",
    "accuracy = 100*clf.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 Stratified Folds for Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    validation_split_num = 1\n",
    "    accuracys = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    skf_split = skf.split(train_images_filenames, train_labels)\n",
    "    skf_split = skf.split(train_images_filenames, train_labels)\n",
    "    for train_index, validation_index in skf_split:\n",
    "        print(validation_split_num)\n",
    "        cv_train_images_filenames = []\n",
    "        cv_train_labels = []\n",
    "        validation_images_filenames = []\n",
    "        validation_labels = []\n",
    "        for index in train_index:\n",
    "            cv_train_images_filenames.append(train_images_filenames[index])\n",
    "            cv_train_labels.append(train_labels[index])                \n",
    "        for index in validation_index:\n",
    "            validation_images_filenames.append(train_images_filenames[index])\n",
    "            validation_labels.append(train_labels[index]) \n",
    "\n",
    "        cv_Train_kpts, cv_Train_descriptors, D = denseSIFT(cv_train_images_filenames, cv_train_labels)\n",
    "        codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "        codebook.fit(D)\n",
    "        visual_words = get_visual_words(cv_Train_descriptors, cv_Train_kpts)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=num_neighbors,n_jobs=-1,metric=knn_metric)\n",
    "        knn.fit(visual_words, cv_train_labels)\n",
    "        \n",
    "        \n",
    "        Validation_kpts, Validation_descriptors, D = denseSIFT(validation_images_filenames, validation_labels)\n",
    "        visual_words_validation = get_visual_words(Validation_descriptors, Validation_kpts)\n",
    "        \n",
    "        accuracy = 100*knn.score(visual_words_validation, validation_labels)\n",
    "        accuracys.append(accuracy)\n",
    "\n",
    "        with open('parameters_execution.log', 'a') as f:\n",
    "            f.write('denseSift: '+str(denseSift)+', '+\n",
    "                    'num_features: '+str(num_features)+', '+\n",
    "                    'k: '+str(k)+', '+\n",
    "                    'num_neighbors: '+str(num_neighbors)+', '+\n",
    "                    'knn_metric: '+str(knn_metric)+', '+\n",
    "                    'step: '+str(step)+', '+\n",
    "                    'pyramidDepth: '+str(pyramidDepth)+', '+\n",
    "                    'validation_split_num: '+str(validation_split_num)+', '+\n",
    "                    'accuracy: '+str(accuracy)+'\\n')\n",
    "        validation_split_num += 1\n",
    "    return accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndict_k = {}\\nfor k in range(100,2001,100): #parameter to be optimized by cv and range \\n    print(k)\\n    acc = evaluate_model()\\n    dict_k[k] = acc\\nprint(dict_k)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dict_k = {}\n",
    "for k in range(100,2001,100): #parameter to be optimized by cv and range \n",
    "    print(k)\n",
    "    acc = evaluate_model()\n",
    "    dict_k[k] = acc\n",
    "print(dict_k)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "- We found that the dataset is balanced and no need for using class_weight for loss claculation while training or any any other solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3kernel",
   "language": "python",
   "name": "m3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
