{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2_Assignment\n",
    "## Team members:\n",
    "- Marc Pérez Quintana  <br>\n",
    "- Basem Elbarashy <br>\n",
    "- Sergi Garcia Bordils <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- We list/explain at the start of each section the defined variables that will be used in the other sections \n",
    "- We assume that you have the following in the current dir:  \n",
    "test/, train/ , test_images_filenames.dat , train_images_filenames.dat, test_labels.dat, train_labels.dat\n",
    "- The code is tested with python 3 and opencv 3.4\n",
    "- Most components are implemented in methods so we can easily play with them at the end of the notebook and tune the hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 400 #number of features for the SIFT detector but for densesift it depends on step value\n",
    "step = 10\n",
    "k = 500 # codebook size / number of clusters for KMeans / number of words\n",
    "num_neighbors = 5 #number of neighbors (k) for the k-nn classifier\n",
    "knn_metric = 'manhattan'#distance for the k-nn classifier\n",
    "denseSift = True #True if Dense SIFT is to be used, False for classical SIFT\n",
    "pyramidDepth = 0 # 0-> No spatial pyramid, 1-> whole image + 4 subimages, 2-> lower levels + 16 subimages, ...\n",
    "\n",
    "\n",
    "normalization = True \n",
    "norm = 'power'  # l2 or power\n",
    "steps = [10]  # [10, 10, 10, 10]  # steps for the different desc sizes\n",
    "kpt_sizes = [10]  # [5, 10, 15, 20]  # desc sizes\n",
    "alpha = 0.75\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Read the train and test files\n",
    "- train_images_filenames\n",
    "- test_images_filenames\n",
    "- train_labels\n",
    "- test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Trainset Size =  1881\n- Trainset classes count :  {'Opencountry': 292, 'coast': 244, 'forest': 227, 'highway': 184, 'inside_city': 214, 'mountain': 260, 'street': 212, 'tallbuilding': 248}\n- Testset Size =  807\n- Testset classes count:  {'Opencountry': 118, 'coast': 116, 'forest': 101, 'highway': 76, 'inside_city': 94, 'mountain': 114, 'street': 80, 'tallbuilding': 108}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n",
    "\n",
    "class_count_test = {}\n",
    "for label in test_labels:\n",
    "    if label in class_count_test:\n",
    "        class_count_test[label] += 1\n",
    "    else: \n",
    "        class_count_test[label] = 1\n",
    "        \n",
    "class_count_train = {}\n",
    "for label in train_labels:\n",
    "    if label in class_count_train:\n",
    "        class_count_train[label] += 1\n",
    "    else: \n",
    "        class_count_train[label] = 1\n",
    "\n",
    "print('- Trainset Size = ', len(train_labels))\n",
    "print(\"- Trainset classes count : \", class_count_train)\n",
    "print('- Testset Size = ', len(test_labels))\n",
    "print(\"- Testset classes count: \", class_count_test)\n",
    "\n",
    "plt.bar(range(len(class_count_train)), list(class_count_train.values()), align='center')\n",
    "plt.xticks(range(len(class_count_train)), list(class_count_train.keys()), rotation='vertical')\n",
    "plt.title('Classes Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\\nskf_split = skf.split(train_images_filenames, train_labels)\\n\\nfor train_index, validation_index in skf_split:\\n    print(\"length of validation_index\", len(validation_index))\\n    print(\"VALIDATION:\", validation_index)\\n    class_count = {}\\n    for index in validation_index:\\n        label = train_labels[index]\\n        if label in class_count:\\n            class_count[label] += 1\\n        else: \\n            class_count[label] = 1\\n    print(class_count)\\n    print(\"-------------------------\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "skf_split = skf.split(train_images_filenames, train_labels)\n",
    "\n",
    "for train_index, validation_index in skf_split:\n",
    "    print(\"length of validation_index\", len(validation_index))\n",
    "    print(\"VALIDATION:\", validation_index)\n",
    "    class_count = {}\n",
    "    for index in validation_index:\n",
    "        label = train_labels[index]\n",
    "        if label in class_count:\n",
    "            class_count[label] += 1\n",
    "        else: \n",
    "            class_count[label] = 1\n",
    "    print(class_count)\n",
    "    print(\"-------------------------\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Dense SIFT\n",
    "- compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denseSIFT(images_filenames, labels):\n",
    "    SIFTdetector = cv2.xfeatures2d.SIFT_create(num_features) # Create a SIFT object detector and descriptor\n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "    kpts = []\n",
    "    \n",
    "    if denseSift:\n",
    "        kpt = []\n",
    "        # I moved this here to avoid computing the kpts for every image, since they all have the same size\n",
    "        for step, size in zip(steps, kpt_sizes):  \n",
    "            kpt.extend([cv2.KeyPoint(x, y, size) for y in range(0, 256, step) \n",
    "                                                 for x in range(0, 256, step)])\n",
    "    \n",
    "    for filename, labels in zip(images_filenames, labels):\n",
    "        filename = filename.replace(\"../../Databases/MIT_split\", \".\")\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if denseSift:\n",
    "            _, des = SIFTdetector.compute(gray, kpt)\n",
    "\n",
    "        else:\n",
    "            kpt, des = SIFTdetector.detectAndCompute(gray, None)\n",
    "        \n",
    "        if normalization:\n",
    "            if norm == 'l2':\n",
    "                des = normalize(des, norm, axis=0)\n",
    "            if norm == 'power':\n",
    "                des = np.sign(des) * (des**alpha)\n",
    "                \n",
    "        kpts.append(kpt)\n",
    "        descriptors.append(des)\n",
    "        label_per_descriptor.append(labels)\n",
    "\n",
    "    return (kpts, descriptors, np.vstack(descriptors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_words(codebook, descriptors, kpts):\n",
    "    for level in range(pyramidDepth+1):\n",
    "        if(level == 0):\n",
    "            pyramid_visual_words = np.zeros((len(descriptors), k), dtype=np.float32)\n",
    "            for i in range(len(descriptors)):\n",
    "                for word in codebook.predict(descriptors[i]):   \n",
    "                    pyramid_visual_words[i,word]+=1\n",
    "        else:\n",
    "            for x in range(2**level):\n",
    "                    for y in range(2**level): \n",
    "                        visual_words=np.zeros((len(descriptors),k),dtype=np.float32)\n",
    "                        for i in range(len(descriptors)):    \n",
    "                            words = codebook.predict(descriptors[i])\n",
    "                            for keypoint in range(len(descriptors[i])):\n",
    "                                x_pt, y_pt = kpts[i][keypoint].pt\n",
    "                                if (x_pt>=x*256/(2**level) and x_pt<(x+1)*256/(2**level) and y_pt>=x*256/(2**level) and y_pt<(x+1)*256/(2**level)):\n",
    "                                    visual_words[i, words[keypoint]]+=1\n",
    "                        pyramid_visual_words = np.append(pyramid_visual_words, (2**level)*visual_words, axis=1)\n",
    "        #print(pyramid_visual_words.shape)\n",
    "    return pyramid_visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramIntersection(M, N):\n",
    "    n,m = M.shape\n",
    "    K_int = np.zeros(shape=(n,n),dtype=np.float)\n",
    "    \n",
    "    print(M.shape, N.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(M.shape[1]):\n",
    "                K_int[i,j] += min(M[i][k],N[j][k])\n",
    "    \n",
    "    return K_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "### Raw data ==> Densesift descriptors ==> Visual words ==> Visual words pyramid ==> Feature standarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata size:  1881\nFeature size:  500\n"
     ]
    }
   ],
   "source": [
    "# Densesift descriptors\n",
    "Train_kpts, Train_descriptors, Train_descriptors_vstacked = denseSIFT(train_images_filenames, train_labels)\n",
    "Test_kpts, Test_descriptors, Test_descriptors_vstacked    = denseSIFT(test_images_filenames,   test_labels)\n",
    "\n",
    "# Visual words\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(Train_descriptors_vstacked)\n",
    "\n",
    "#  Visual words pyramid\n",
    "visual_words_train = get_visual_words(codebook, Train_descriptors, Train_kpts)\n",
    "visual_words_test  = get_visual_words(codebook, Test_descriptors, Test_kpts)\n",
    "\n",
    "# Feature standarization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(visual_words_train)\n",
    "visual_words_train = scaler.transform(visual_words_train)\n",
    "visual_words_test  = scaler.transform(visual_words_test)\n",
    "\n",
    "# Compare between data size and feature size\n",
    "print('traindata size: ',visual_words_train.shape[0])\n",
    "print('Feature size: ',visual_words_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.74721189591078\n"
     ]
    }
   ],
   "source": [
    "## Knn classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=num_neighbors,n_jobs=-1,metric=knn_metric)\n",
    "knn.fit(visual_words_train, train_labels)\n",
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.14745972738538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n## SVM classifier with SGD!\\nclf = SGDClassifier(alpha=.0001, n_iter=60, penalty='l2', shuffle=True, random_state=0,verbose=0)\\nclf.fit(visual_words, train_labels)\\naccuracy = 100*clf.score(visual_words_test, test_labels)\\nprint(accuracy)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SVM classifier\n",
    "svm_kernel = 'rbf'  # It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable \n",
    "clf = svm.SVC(kernel=svm_kernel, C = 1)\n",
    "clf.fit(visual_words_train, train_labels)\n",
    "accuracy = 100*clf.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "\"\"\"\n",
    "## SVM classifier with SGD!\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=60, penalty='l2', shuffle=True, random_state=0,verbose=0)\n",
    "clf.fit(visual_words, train_labels)\n",
    "accuracy = 100*clf.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 Stratified Folds for Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    validation_split_num = 1\n",
    "    accuracys = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    skf_split = skf.split(train_images_filenames, train_labels)\n",
    "    skf_split = skf.split(train_images_filenames, train_labels)\n",
    "    for train_index, validation_index in skf_split:\n",
    "        print(validation_split_num)\n",
    "        cv_train_images_filenames = []\n",
    "        cv_train_labels = []\n",
    "        validation_images_filenames = []\n",
    "        validation_labels = []\n",
    "        for index in train_index:\n",
    "            cv_train_images_filenames.append(train_images_filenames[index])\n",
    "            cv_train_labels.append(train_labels[index])                \n",
    "        for index in validation_index:\n",
    "            validation_images_filenames.append(train_images_filenames[index])\n",
    "            validation_labels.append(train_labels[index]) \n",
    "\n",
    "        cv_Train_kpts, cv_Train_descriptors, D = denseSIFT(cv_train_images_filenames, cv_train_labels)\n",
    "        Validation_kpts, Validation_descriptors, D = denseSIFT(validation_images_filenames, validation_labels)\n",
    "        \n",
    "        codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "        codebook.fit(D)\n",
    "        \n",
    "        visual_words = get_visual_words(codebook, cv_Train_descriptors, cv_Train_kpts)\n",
    "        visual_words_validation = get_visual_words(codebook, Validation_descriptors, Validation_kpts)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=num_neighbors,n_jobs=-1,metric=knn_metric)\n",
    "        knn.fit(visual_words, cv_train_labels)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(visual_words)\n",
    "        visual_words = scaler.transform(visual_words)\n",
    "        visual_words_validation = scaler.transform(visual_words_validation)\n",
    "\n",
    "        accuracyKNN = 100*knn.score(visual_words_validation, validation_labels)\n",
    "        \n",
    "        ## SVM classifier\n",
    "        svm_kernel = 'rbf'  # It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable \n",
    "        clf = svm.SVC(kernel=svm_kernel, C = 1)\n",
    "        clf.fit(visual_words, cv_train_labels)\n",
    "        accuracySVM = 100*clf.score(visual_words_validation, validation_labels)\n",
    "        accuracys.append(accuracySVM)\n",
    "\n",
    "        with open('parameters_execution.log', 'a') as f:\n",
    "            f.write('denseSift: '+str(denseSift)+', '+\n",
    "                    'num_features: '+str(num_features)+', '+\n",
    "                    'k: '+str(k)+', '+\n",
    "                    'num_neighbors: '+str(num_neighbors)+', '+\n",
    "                    'knn_metric: '+str(knn_metric)+', '+\n",
    "                    'step: '+str(step)+', '+\n",
    "                    'pyramidDepth: '+str(pyramidDepth)+', '+\n",
    "                    'validation_split_num: '+str(validation_split_num)+', '+\n",
    "                    'normalization: '+str(normalization)+', '+\n",
    "                    'norm: '+str(norm)+', '+\n",
    "                    'alpha: '+str(alpha)+', '+\n",
    "                    'kpt_sizes: '+str(kpt_sizes)+', '+\n",
    "                    'accuracySVM: '+str(accuracySVM)+', '+\n",
    "                    'accuracyKNN: '+str(accuracyKNN)+'\\n')\n",
    "        validation_split_num += 1\n",
    "\n",
    "    return accuracys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "dict_k = {}\n",
    "for k in range(100,2001,100): #parameter to be optimized by cv and range \n",
    "    print(k)\n",
    "    acc = evaluate_model()\n",
    "    dict_k[k] = acc\n",
    "    print(dict_k)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_model()\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "- We found that the dataset is balanced and no need for using class_weight for loss claculation while training or any any other solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3kernel",
   "language": "python",
   "name": "m3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
