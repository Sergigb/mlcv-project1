{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2_Assignment\n",
    "## Team members:\n",
    "- Marc PÃ©rez Quintana  <br>\n",
    "- Basem Elbarashy <br>\n",
    "- Sergi Garcia Bordils <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- We list/explain at the start of each section the defined variables that will be used in the other sections \n",
    "- We assume that you have the following in the current dir:  \n",
    "test/, train/ , test_images_filenames.dat , train_images_filenames.dat, test_labels.dat, train_labels.dat\n",
    "- The code is tested with python 3 and opencv 3.4\n",
    "- Most components are implemented in methods so we can easily play with them at the end of the notebook and tune the hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 400 #number of features for the SIFT detector but for densesift it depends on step value\n",
    "step = 10\n",
    "k = 500 # codebook size / number of clusters for KMeans / number of words\n",
    "num_neighbors = 5 #number of neighbors (k) for the k-nn classifier\n",
    "knn_metric = 'manhattan'#distance for the k-nn classifier\n",
    "denseSift = True #True if Dense SIFT is to be used, False for classical SIFT\n",
    "pyramidDepth = 0 # 0-> No spatial pyramid, 1-> whole image + 4 subimages, 2-> lower levels + 16 subimages, ...\n",
    "\n",
    "\n",
    "normalization = True \n",
    "norm = 'power'  # l2 or power\n",
    "steps = [10]  # [10, 10, 10, 10]  # steps for the different desc sizes\n",
    "kpt_sizes = [10]  # [5, 10, 15, 20]  # desc sizes\n",
    "alpha = 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Read the train and test files\n",
    "- train_images_filenames\n",
    "- test_images_filenames\n",
    "- train_labels\n",
    "- test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Trainset Size =  1881\n",
      "- Trainset classes count :  {'forest': 227, 'street': 212, 'coast': 244, 'mountain': 260, 'tallbuilding': 248, 'Opencountry': 292, 'highway': 184, 'inside_city': 214}\n",
      "- Testset Size =  807\n",
      "- Testset classes count:  {'forest': 101, 'street': 80, 'coast': 116, 'mountain': 114, 'tallbuilding': 108, 'Opencountry': 118, 'highway': 76, 'inside_city': 94}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n",
    "\n",
    "class_count_test = {}\n",
    "for label in test_labels:\n",
    "    if label in class_count_test:\n",
    "        class_count_test[label] += 1\n",
    "    else: \n",
    "        class_count_test[label] = 1\n",
    "        \n",
    "class_count_train = {}\n",
    "for label in train_labels:\n",
    "    if label in class_count_train:\n",
    "        class_count_train[label] += 1\n",
    "    else: \n",
    "        class_count_train[label] = 1\n",
    "\n",
    "print('- Trainset Size = ', len(train_labels))\n",
    "print(\"- Trainset classes count : \", class_count_train)\n",
    "print('- Testset Size = ', len(test_labels))\n",
    "print(\"- Testset classes count: \", class_count_test)\n",
    "\n",
    "plt.bar(range(len(class_count_train)), list(class_count_train.values()), align='center')\n",
    "plt.xticks(range(len(class_count_train)), list(class_count_train.keys()), rotation='vertical')\n",
    "plt.title('Classes Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\\nskf_split = skf.split(train_images_filenames, train_labels)\\n\\nfor train_index, validation_index in skf_split:\\n    print(\"length of validation_index\", len(validation_index))\\n    print(\"VALIDATION:\", validation_index)\\n    class_count = {}\\n    for index in validation_index:\\n        label = train_labels[index]\\n        if label in class_count:\\n            class_count[label] += 1\\n        else: \\n            class_count[label] = 1\\n    print(class_count)\\n    print(\"-------------------------\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "skf_split = skf.split(train_images_filenames, train_labels)\n",
    "\n",
    "for train_index, validation_index in skf_split:\n",
    "    print(\"length of validation_index\", len(validation_index))\n",
    "    print(\"VALIDATION:\", validation_index)\n",
    "    class_count = {}\n",
    "    for index in validation_index:\n",
    "        label = train_labels[index]\n",
    "        if label in class_count:\n",
    "            class_count[label] += 1\n",
    "        else: \n",
    "            class_count[label] = 1\n",
    "    print(class_count)\n",
    "    print(\"-------------------------\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Dense SIFT\n",
    "- compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denseSIFT(images_filenames, labels):\n",
    "    SIFTdetector = cv2.xfeatures2d.SIFT_create(num_features) # Create a SIFT object detector and descriptor\n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "    kpts = []\n",
    "    \n",
    "    if denseSift:\n",
    "        kpt = []\n",
    "        # I moved this here to avoid computing the kpts for every image, since they all have the same size\n",
    "        for step, size in zip(steps, kpt_sizes):  \n",
    "            kpt.extend([cv2.KeyPoint(x, y, size) for y in range(0, 256, step) \n",
    "                                             for x in range(0, 256, step)])\n",
    "    \n",
    "    for filename, labels in zip(images_filenames, labels):\n",
    "        filename = filename.replace(\"../../Databases/MIT_split\", \".\")\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if denseSift:\n",
    "            _, des = SIFTdetector.compute(gray, kpt)\n",
    "\n",
    "        else:\n",
    "            kpt, des = SIFTdetector.detectAndCompute(gray, None)\n",
    "        \n",
    "        if normalization:\n",
    "            if norm == 'l2':\n",
    "                des = normalize(des, norm, axis=0)\n",
    "            if norm == 'power':\n",
    "                des = np.sign(des) * (des**alpha)\n",
    "                \n",
    "        kpts.append(kpt)\n",
    "        descriptors.append(des)\n",
    "        label_per_descriptor.append(labels)\n",
    "\n",
    "    return (kpts, descriptors, np.vstack(descriptors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_words(codebook, descriptors, kpts):\n",
    "    for level in range(pyramidDepth+1):\n",
    "        if(level == 0):\n",
    "            pyramid_visual_words = np.zeros((len(descriptors), k), dtype=np.float32)\n",
    "            for i in range(len(descriptors)):\n",
    "                for word in codebook.predict(descriptors[i]):   \n",
    "                    pyramid_visual_words[i,word]+=1\n",
    "            #pyramid_visual_words = pyramid_visual_words / pyramid_visual_words.sum()\n",
    "            print(\"level 0 ->>>>>> \"+str(pyramid_visual_words.sum()))\n",
    "        else:\n",
    "            for x in range(2**level):\n",
    "                    for y in range(2**level): \n",
    "                        visual_words=np.zeros((len(descriptors),k),dtype=np.float32)\n",
    "                        for i in range(len(descriptors)):    \n",
    "                            words = codebook.predict(descriptors[i])\n",
    "                            for keypoint in range(len(kpts[i])):\n",
    "                                x_pt, y_pt = kpts[i][keypoint].pt\n",
    "                                if (x_pt>=x*256/(2**level) and x_pt<(x+1)*256/(2**level) and y_pt>=y*256/(2**level) and y_pt<(y+1)*256/(2**level)):\n",
    "                                    visual_words[i, words[keypoint]]+=1\n",
    "                        #visual_words = visual_words/visual_words.sum()\n",
    "                        pyramid_visual_words = np.append(pyramid_visual_words, visual_words, axis=1)\n",
    "                        print(\"level \"+str(level)+\",x \"+str(x)+\",y \"+str(y)+\": \"+str(visual_words.sum()))\n",
    "                        print(x*256/(2**level), (x+1)*256/(2**level), y*256/(2**level), (y+1)*256/(2**level))\n",
    "        #print(pyramid_visual_words.shape)\n",
    "    return pyramid_visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramIntersection(M, N):\n",
    "    n,m = M.shape\n",
    "    K_int = np.zeros(shape=(n,n),dtype=np.float)\n",
    "    \n",
    "    print(M.shape, N.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(M.shape[1]):\n",
    "                K_int[i,j] += min(M[i][k],N[j][k])\n",
    "    \n",
    "    return K_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "### Raw data ==> Densesift descriptors ==> Visual words ==> Visual words pyramid ==> Feature standarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densesift descriptors\n",
    "Train_kpts, Train_descriptors, Train_descriptors_vstacked = denseSIFT(train_images_filenames, train_labels)\n",
    "Test_kpts, Test_descriptors, Test_descriptors_vstacked    = denseSIFT(test_images_filenames,   test_labels)\n",
    "\n",
    "# Visual words\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(Train_descriptors_vstacked)\n",
    "\n",
    "#  Visual words pyramid\n",
    "visual_words_train = get_visual_words(codebook, Train_descriptors, Train_kpts)\n",
    "visual_words_test  = get_visual_words(codebook, Test_descriptors, Test_kpts)\n",
    "\n",
    "# Feature standarization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(visual_words_train)\n",
    "visual_words_train = scaler.transform(visual_words_train)\n",
    "visual_words_test  = scaler.transform(visual_words_test)\n",
    "\n",
    "# Compare between data size and feature size\n",
    "print('traindata size: ',visual_words_train.shape[0])\n",
    "print('Feature size: ',visual_words_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Knn classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=num_neighbors,n_jobs=-1,metric=knn_metric)\n",
    "knn.fit(visual_words_train, train_labels)\n",
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM classifier\n",
    "svm_kernel = 'rbf'  # It must be one of âlinearâ, âpolyâ, ârbfâ, âsigmoidâ, âprecomputedâ or a callable \n",
    "clf = svm.SVC(kernel=svm_kernel, C = 1)\n",
    "clf.fit(visual_words_train, train_labels)\n",
    "accuracy = 100*clf.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "\"\"\"\n",
    "## SVM classifier with SGD!\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=60, penalty='l2', shuffle=True, random_state=0,verbose=0)\n",
    "clf.fit(visual_words, train_labels)\n",
    "accuracy = 100*clf.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5 Stratified Folds for Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    validation_split_num = 1\n",
    "    accuracys = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    skf_split = skf.split(train_images_filenames, train_labels)\n",
    "    skf_split = skf.split(train_images_filenames, train_labels)\n",
    "    for train_index, validation_index in skf_split:\n",
    "        print(validation_split_num)\n",
    "        cv_train_images_filenames = []\n",
    "        cv_train_labels = []\n",
    "        validation_images_filenames = []\n",
    "        validation_labels = []\n",
    "        for index in train_index:\n",
    "            cv_train_images_filenames.append(train_images_filenames[index])\n",
    "            cv_train_labels.append(train_labels[index])                \n",
    "        for index in validation_index:\n",
    "            validation_images_filenames.append(train_images_filenames[index])\n",
    "            validation_labels.append(train_labels[index]) \n",
    "\n",
    "        cv_Train_kpts, cv_Train_descriptors, D = denseSIFT(cv_train_images_filenames, cv_train_labels)\n",
    "        Validation_kpts, Validation_descriptors, D = denseSIFT(validation_images_filenames, validation_labels)\n",
    "        \n",
    "        codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "        codebook.fit(D)\n",
    "        \n",
    "        visual_words = get_visual_words(codebook, cv_Train_descriptors, cv_Train_kpts)\n",
    "        visual_words_validation = get_visual_words(codebook, Validation_descriptors, Validation_kpts)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=num_neighbors,n_jobs=-1,metric=knn_metric)\n",
    "        knn.fit(visual_words, cv_train_labels)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(visual_words)\n",
    "        visual_words = scaler.transform(visual_words)\n",
    "        visual_words_validation = scaler.transform(visual_words_validation)\n",
    "\n",
    "        accuracyKNN = 100*knn.score(visual_words_validation, validation_labels)\n",
    "        \n",
    "        ## SVM classifier\n",
    "        svm_kernel = 'rbf'  # It must be one of âlinearâ, âpolyâ, ârbfâ, âsigmoidâ, âprecomputedâ or a callable \n",
    "        clf = svm.SVC(kernel=svm_kernel, C = 1)\n",
    "        clf.fit(visual_words, cv_train_labels)\n",
    "        accuracySVM = 100*clf.score(visual_words_validation, validation_labels)\n",
    "        accuracys.append(accuracySVM)\n",
    "\n",
    "        with open('parameters_execution.log', 'a') as f:\n",
    "            f.write('denseSift: '+str(denseSift)+', '+\n",
    "                    'num_features: '+str(num_features)+', '+\n",
    "                    'k: '+str(k)+', '+\n",
    "                    'num_neighbors: '+str(num_neighbors)+', '+\n",
    "                    'knn_metric: '+str(knn_metric)+', '+\n",
    "                    'step: '+str(step)+', '+\n",
    "                    'pyramidDepth: '+str(pyramidDepth)+', '+\n",
    "                    'validation_split_num: '+str(validation_split_num)+', '+\n",
    "                    'normalization: '+str(normalization)+', '+\n",
    "                    'norm: '+str(norm)+', '+\n",
    "                    'alpha: '+str(alpha)+', '+\n",
    "                    'kpt_sizes: '+str(kpt_sizes)+', '+\n",
    "                    'accuracySVM: '+str(accuracySVM)+', '+\n",
    "                    'accuracyKNN: '+str(accuracyKNN)+'\\n')\n",
    "        validation_split_num += 1\n",
    "\n",
    "    return accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dict_k = {}\n",
    "for k in range(100,2001,100): #parameter to be optimized by cv and range \n",
    "    print(k)\n",
    "    acc = evaluate_model()\n",
    "    dict_k[k] = acc\n",
    "print(dict_k)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluate_model()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "- We found that the dataset is balanced and no need for using class_weight for loss claculation while training or any any other solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3kernel",
   "language": "python",
   "name": "m3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
